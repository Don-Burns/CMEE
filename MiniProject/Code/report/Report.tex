%&latexf
\documentclass[a4paper]{article}
\usepackage{color}
\setlength{\hoffset}{-0.5in}\hoffset-0.5in
\setlength{\textwidth}{15cm}
\usepackage{hyperref}

\usepackage{verbatim}
\usepackage{stmaryrd}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage[dvips]{graphicx}
\usepackage{subfigure}


%my packages
\usepackage{amsmath, amsfonts, amsthm, amssymb}
\usepackage{csvsimple, longtable, booktabs}
\usepackage{filecontents}

\usepackage[displaymath, mathlines]{lineno}





\linespread{1.5}
%\font\twelvemsb=msbm10 at 12pt
\newfam\msbfam
%\textfont\msbfam=\twelvemsb
\def\Bbb#1{\fam\msbfam\relax#1}

\topmargin = 20pt
\voffset = -20pt
\addtolength{\textheight}{2cm}




%% word count command
\newcommand\wordcount{\input{Report.sum}}

%biblio







\def\equalDistrib{\,{\buildrel \Delta \over =}\,}
\numberwithin{equation}{section}
\def\blue#1{\textcolor{blue}{#1}}
\def\red#1{\textcolor{red}{#1}}


\begin{document}
	\begin{titlepage}
		\thispagestyle{empty}
		\null\vskip0.2in
		\begin{center}
		\LARGE{{\bf 
		Mini Project}}
		\end{center}

		\vspace{0.5cm}

		\begin{center}
		{\Large {\bf by}}\\
		\mbox{} \\
		{\Large {\bf D\'onal Burns (CID: 01749638)}}
		\newline
		{\Large {\bf PUT IN LINE NUMBERS}}
		\end{center}

		\vspace{1cm}

		\begin{center}
		\large{\bf{Department of Life Sciences \\ Imperial College London \\
		London SW7 2AZ \\ United Kingdom}}
		\end{center}


		\vspace{1.5cm}

		\begin{figure}[!h]
		\centering
		%\includegraphics[scale=0.4]{IC_Crest.eps}
		\end{figure}

		\vspace{1.5cm}

		\begin{center}
		\large{\bf{Report submitted as part of the MSc in Computation Methods in Ecology and Evolution, Imperial College London, 2019-2020}}
		\end{center}

		\vspace{2cm}
		
		\begin{center}
		\large{Word Count: \wordcount}
		\end{center}


\end{titlepage}
%\include{ThesisFrontPage}
%\include{ThesisAcknowledgements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\text{}\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{tocdepth}{4}
\tableofcontents
\newpage
%\newpage
%\include{ThesisNotations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fancyhead{}
\fancyfoot{}
\pagestyle{fancy} 
%\fancyhead{\sffamily\small \thepage}
%\fancyhead{\sffamily\small \nouppercase{\rightmark}}
\fancyhead[RO,LE]{\sffamily\small \thepage}
\fancyhead[LO,RE]{\sffamily\small \nouppercase{\rightmark}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.0pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\include{Thesis_Part1_Introduction}
%\include{Thesis_Part2_Tools}
%\include{Thesis_Part3_Large}
%\include{Thesis_Part4_Small}



\linenumbers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Describe paper goals and what it is about


A functional response is the manner in which a consumer’s rate of consumption changes with the density of resources\cite{Dunn2020}.   The concept was mathematically described by Holling in 1959\cite{Holling1959, Holling1959a} .  Holling separated functional responses into three broad categories; type I, type II and type III \cite{Holling1959, Holling1959a}.  Holling’s original model was later built upon by Real to be able to describe all three type of functional response \cite{Real1977, Real1979}.  All three functional response type can be described by the equation: 
\newline
[Equation 1] 
\newline 
Generalised Model

\begin{equation} 
N_e = \frac{aN_0^{q+1}}{1+ahN0^{q+1}}\label{general}
\end{equation}
Type III
\begin{equation} 
N_e = \frac{aN_0^2}{1+ahN_0^2}\label{typeIII}
\end{equation}
Type II
\begin{equation}
N_e = \frac{aN_0}{1+ahN0}\label{typeII}
\end{equation}
Type I
\begin{equation}
N_e = aN_0 \label{typeI}
\end{equation}


[equation formatting and reference, also need to check how it should be in the rest of the text ]\eqref{typeIII}
\newline
Where $N_e$ is consumption rate, $N_0$ is resource density, $a$ is the attack rate or how fast the consumer comes in contact with resources, $h$ is handling time or how long the consumer spends with a “piece” of resource before being able to continue searching and $q$ is a dimensionless parameter which attempts to capture a lag phase at low resource densities.
Sources for above
\newline
Type I responses have only been observed in filter feeders\cite{Jeschke2004}.  The response is characterised by a linear increase up to a threshold, at which the rate of consumption remains constant [response types graph].  In a type I response handling time is thought to be nearly instantaneous (i.e. $h = 0$).  This results in [equation 1] becoming;
 $N_e = aN_0$ \cite{Dunn2020}.  
Meaning that consumption rate and resource density are the only factors affecting consumption rate.  In other words, the consumer is essentially able to acquire resources and handle resources simultaneously.  The reason why this pattern is only observed in some filter feeders is because only filter feeders are capable of both having a negligibly small handling time and is able to search for resources while handling other food \cite{Jeschke2004}.
\newline
Type II functional responses are described as having a steep increase at low resource densities as handling time is not a limiting factor.  Consumption rate steadily levels out as resource density increases and handling time becomes more and more of a limiting factor, eventually reaching a maximum value that is dependant on handling time [response graph].  Maximum consumption rate can be descibed as:
$N_{e \ max} = \frac{1}{h}$ \cite{Rosenbaum2018}.
\newline
In a type II response $q = 0$ as there is no “lag phase” in consumption rate.  This results in equation 1 becoming:
 $N_e = aN_0  / 1+ahN_0$  \cite{Rosenbaum2018, Dunn2020}.
\newline
The theory behind a type III response follows mostly the same as type II.  Type III responses will also increase until reaching a maximum rate of consumption which is limited by handling time.  However, type III responses have a “lag phase” at low resource densities.  It is $q$ which allows equation 1 to capture this.  In a strict type III functional response $q = 1$ \cite{Rosenbaum2018}.  The resulting equation is:
$N_e = aN_0^2  / 1+ahN_0^2$
\newline
In order to investigate how recorded data fits into the above, it is necessary to fit the respective models to the data and determine which is the best fit.  The above models can be described as mechanistic models.  Meaning that the parameters are based on biological factors or mechanisms.  An alternative outlook is to derive an equation which fits the observed data as good as possible without the need to be based on biological mechanisms.  These are called phenomenological models.  Which of these approaches is best is a topic of debate and can depend on the data being used or question being asked.  
\newline
Include something about boom bust unstable pop under type II and stable pop under type III \cite{Vucic-Pestic2010}.
\newline
This all leads to allowing this study to look at, on a very abstract level, whether there is any difference between which model best fits consumers in different habitats.  Here marine, freshwater and terrestrial consumer data will be and any difference that can be found discussed.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Methods}
The data was taken from the biotraits database.  This database collects resource denstity and consumption rate from the literature and stores the resulting data in both the original units of the study in question and standardised units, so as to be comparable to other data points collected in the database.  The fits were performed using this standardised data.  The data comes in the form that each study is given a unique ID number so as to identify data points which come from the same study(totalling 308 unique ID numbers).  Additionally, information is stored about many other factors such as resource mass, resource type and, of interest for this study, consumer habitat. 
\newline 
For this study, so as to compare mechanistic and phenomenological models, Holling's equations were used as mechanistic models while polynomials were used a phenomelogical models.  This was done to see how the Holling models will fit in comparison to models which produce similar shapes.  Quadratic and cubic polynomials were fitted, where a Quadratic polynomial produces a shape that is similar to that of a type II functional response.  Likewise, a cubic polynomial follows a similar shape to that of a Type III functional response.  It is worth noting that due to the properties of polynomials, they cannot form a straight line at a maximum in the same way as the Holling models and must either continue to increase or decrease at a point of inflection.  As a results polynomials is expected to best fit data which either does not have enough data points to show the theoretical maximum consumption rate expected under the Holling models or there is some decline in the data once this maximum is reached, possible due to the consumer slowing down due to consuming too much in a short time during the experiments the data was derived from.
\newline
For the model fits to be performed, the data was first split based on the trait of interest.  This was done both for speed when fitting the data and so data could be manually inspected for abnormalities before fitting.  Each subset was then run through the fitting process.  This process involves grouping the data points from each unique ID number and running the data through a fitting function.  For the “Holling models” starting values were estimated before fitting. 
\newline 
$a$ was estimated by fitting a line to the steepest section of the data and taking the slope of the line.  The logic behind this is that under a type I response a is the only factor which influences consumption rate and the line until the threshold is reached is defined as a straight line with a slop of a.  With this logic, the same can be said for type II and type III responses where the steepest portion of the functional response is the section at which a’s influence is maximised and the influence of both q and h is at a minimum.  This value was obtained by fitting a straight line to the data and calculating the slope of the line and the residual sum of squares (RSS) between the line and the data.  The same process was then run again, but with the data point with the highest resource density removed.  The RSS was then calculated and compared to the previous result.  If the RSS was lower than the previous result then the slope of the new line is stored instead and the process was repeated, this time with the two highest resource density data points removed.  This was repeated until only three or 30\% of the data points from the original data remained.  Three data points was chosen as the threshold as any less was nearly guaranteed to be the line with the lowest RSS as the line generated is a line between those final two points.  The reason that 30\% was used was that some data sets contained data which was recorded many times at fixed resource densities.  Under the above method with three data points as the threshold, this vastly overestimated a.  30\% was found to be a value where the fitting process was impacted by the starting parameter obtained from these data sets.
\newline
H was estimated as the inverse of the maximum observed rate of consumption, i.e. $$h = 1/N_{e \ max}$$ \cite{Rosenbaum2018}[ Rosenbaum and Rall 2018]. 
\newline 
When fitting using q, a starting value of 0 was used. 
\newline 
The models were then fit to the data using lmfit.minimize in python [lmfit ref].  This uses a least-squares method to find the parameter values that best fit the observed data.  So as to ensure that the fitting algorithm did not “get stuck” in local minima when fitting, the fitting process was repeated with varying starting parameters 100 times.  Each of these repeats a and h were set as random numbers chosen from a random distribution ranging from 50\% to 150\% of the initial parameter estimate.  The starting q value was set as a random number chosen from a uniform distribution ranging from zero to one.  The parameter set which yielded the best Akaike information criterion (AIC) value was taken to contain the parameters which best captured the data.  
\newline
In order to fit polynomials to the data PolynomialModel from lmfit is used.  This is a wrapper around numpy.polyval which uses Horner’s scheme as a means of estimating the polynomial coefficients.  Since this is a deterministic process the fits were not repeated for polynomial models.
$$
[include the graph of the output]
$$
After fitting any values which were not biologically viable for the two hollings models were removed (i.e. value of attack rate or handling time $\leq$ 0).
The results were analysed by calculating which models best fit each dataset using AIC values.  The best model for each dataset was determined by selecting the model with the lowest AIC.  Following the rule of thumb, best model was only determined if the lowest AIC value was two less than all other AIC values for the given dataset \cite{Burnham2004}\cite{Johnson2004}

$$Typically Because there are over 200 fits for each model type, rather than using the convention of models much have a difference in AIC of at least two to be considered different, it was decided to look at the "big picture" by taking any difference in AIC to determine which model fit the data best.  The results were recorded when taking best AIC values (i.e. lowest) overall and for each consumer habitat present in the dataset (terrestrial, marine and aquatic).$$

\subsection{Computing tools}
All model fitting and plotting was carried out using the $lmift$ (version 0.9.14) and matplotlib (version 3.1.1) packages respectively  alongside scipy (0.19.1) and pandas (0.25.3) for data manipulation in Python 3.6.9.  

R (version 3.6.3) was used to carry out the analysis with dplyr (version 0.8.3) for data manipulation. 






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Results}
The results of the model fitting found that in all cases a third-degree polynomial best fit the data.  The generalised holling model fit second most followed by Holling's original model and finally a second-degree polynomial was found to fit none of the data best.  However, if the cubic model is removed from the data set the then the quadratic model is found to fit best in all cases. If the phenomenological models are removed from the analysis, it can be seen that a type II functional response best fits the data.
$$ 
table of the results with polynomials
$$  
\newline
Out of the 308 datasets that were present in the data eighteen were removed due to the generalised model not converging during the fitting process, leaving 290 datasets to be used for the analysis.  Of these, the best model using AIC values was able to be determined for 214 datasets.  
$$
table with no polys
$$
\newline
$q$ values for the generalised model had a mean of 0.87 (minimum: $<$0.001, maximum: 30.81, variance: 5.90).  While values did exceed $q=1$, which would result in a strict type III functional response \cite{Rosenbaum2018}, q values mostly lay between zero and one (221 of 279 values, with biologically unviable and non-convergent datasets removed).

$$
talk about q range and mean
put q histogram here
$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Discussion}
Cubic polynomials performing the best overall is not unexpected.  A polynomial will always fit the data as best as possible within the constraints of its degree.  This included not obeying biological constraints or rules where more mechanistic models must. $refer to a graph of cubic doing as it pleases to fit$
There are also claims that the Holling models are themselves not mechanistic, rather that they while the models are based in biology the description of "handling time" is too vague as it contains both active, resource capture and acquisition, and passive actions, digestion, and as such cannot be mechanistic \cite{Jeschke2002a}.  Since Holling developed his original model in 1959\cite{Holling1959} and its generalisation by Real in 1977\cite{Real1977}, other "more mechanistic" models have been developed which \cite{Jeschke2002a} (several mentioned in \cite{Rosenbaum2018}).  
\newline



$$ insert graph of cubic going mental but fitting data points well$$






\newpage
\section{Conclusion}











\newpage
\appendix{}
\section{Plots}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
%\include{ThesisConclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{MiniProject.bib}{}
\bibliographystyle{plain}
\end{document}
